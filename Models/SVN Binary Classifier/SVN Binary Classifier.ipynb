{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f1d324-c599-4f0c-8afa-8ea16b58eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /opt/conda/lib/python3.12/site-packages (from opencv-python) (2.0.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (0.21.0+cu126)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.12/site-packages (2.0.10)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "#SVN is used to classify for sparse datasets with binary classification\n",
    "#downloading stuff\n",
    "#install stuff\n",
    "!pip install opencv-python\n",
    "!pip install torch torchvision pycocotools matplotlib scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d4da5-39db-4d3b-905f-93972a7069d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#References\n",
    "#1. https://www.geeksforgeeks.org/machine-learning/classifying-data-using-support-vector-machinessvms-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41cfc478-6bb0-43d5-970f-b9140099ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52319f4d-b5a7-472d-9c1a-fd1ccd0bc11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n",
      "['.config', '.local', 'Image Augmentation', '.jupyter', 'model_experimentation', 'shared', 'Github Repo', 'Untitled.ipynb', 'Annotated_ImageSets', '.ipynb_checkpoints', '.keras', '.ipython', 'SVN Binary Classificer', 'UNET Segmentatoin', 'Untitled Folder', '.cache']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '100_annotated_pins_for_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# lists files/folders in current directory\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m100_annotated_pins_for_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# lists files in your folder\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '100_annotated_pins_for_model'"
     ]
    }
   ],
   "source": [
    "#troubleshooting\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir('.'))  # lists files/folders in current directory\n",
    "print(os.listdir('100_annotated_pins_for_model'))  # lists files in your folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96e97e72-a1cf-47d6-8ddc-ef5a2ca919e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/SVN Binary Classificer/100_annotated_pins_for_modeldata/train_data.csv\n",
      "/home/jovyan/SVN Binary Classificer/100_annotated_pins_for_modeldata/validtn_data.csv\n",
      "/home/jovyan/UNET Segmentatoin/100_annotated_pins_for_model/data/validtn_data.csv\n",
      "/home/jovyan/UNET Segmentatoin/100_annotated_pins_for_model/data/train_data.csv\n",
      "/home/jovyan/UNET Segmentatoin/data/validtn_data.csv\n",
      "/home/jovyan/UNET Segmentatoin/data/train_data.csv\n",
      "/home/jovyan/UNET Segmentatoin/100_annotated_pins_for_modeldata/train_data.csv\n",
      "/home/jovyan/UNET Segmentatoin/100_annotated_pins_for_modeldata/validtn_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Look for CSV files under the base directory\n",
    "for root, dirs, files in os.walk('/home/jovyan'):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead7a0c2-19bd-4c62-95cc-4418bfe65c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CSV columns: Index(['filepath'], dtype='object')\n",
      "                                            filepath\n",
      "0  100_annotated_pins_for_model/IMG_7046_flat_02_...\n",
      "1  100_annotated_pins_for_model/IMG_7392_flat_00_...\n",
      "2  100_annotated_pins_for_model/IMG_7311_flat_00_...\n",
      "3  100_annotated_pins_for_model/IMG_7043_flat_00_...\n",
      "4  100_annotated_pins_for_model/IMG_4875_flat_00_...\n",
      "Valid CSV columns: Index(['filepath'], dtype='object')\n",
      "                                            filepath\n",
      "0  100_annotated_pins_for_model/IMG_2937_flat_01_...\n",
      "1  100_annotated_pins_for_model/IMG_2934_flat_01_...\n",
      "2  100_annotated_pins_for_model/IMG_7910_flat_00_...\n",
      "3  100_annotated_pins_for_model/IMG_5262_flat_00_...\n",
      "4  100_annotated_pins_for_model/IMG_4874_flat_01_...\n",
      "Number of training samples: 175\n",
      "Number of validation samples: 31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Correct paths\n",
    "train_csv_path = '/home/jovyan/SVN Binary Classificer/100_annotated_pins_for_modeldata/train_data.csv'\n",
    "valid_csv_path = '/home/jovyan/SVN Binary Classificer/100_annotated_pins_for_modeldata/validtn_data.csv'\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "valid_df = pd.read_csv(valid_csv_path)\n",
    "\n",
    "# Check the first few rows and columns\n",
    "print(\"Train CSV columns:\", train_df.columns)\n",
    "print(train_df.head())\n",
    "print(\"Valid CSV columns:\", valid_df.columns)\n",
    "print(valid_df.head())\n",
    "\n",
    "# Prepare image file paths\n",
    "X_train = train_df['filepath'].values\n",
    "X_valid = valid_df['filepath'].values\n",
    "\n",
    "# If you have masks in CSV, uncomment and adjust these lines:\n",
    "# y_train = train_df['rle_1'].values  # adjust column names if needed\n",
    "# y_valid = valid_df['rle_1'].values\n",
    "\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of validation samples:\", len(X_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed552b3-e8de-4423-a537-923e7ba75988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (175, 128, 128, 3)\n",
      "Validation shape: (31, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Base folder where images actually exist\n",
    "base_dir = '/home/jovyan/SVN Binary Classificer/100_annotated_pins_for_model2'\n",
    "\n",
    "# Fix CSV paths\n",
    "def fix_path(csv_path):\n",
    "    # Take only the filename from the CSV path\n",
    "    filename = os.path.basename(csv_path)\n",
    "    return os.path.join(base_dir, filename)\n",
    "\n",
    "X_train_paths = train_df['filepath'].apply(fix_path)\n",
    "X_valid_paths = valid_df['filepath'].apply(fix_path)\n",
    "\n",
    "# Parameters\n",
    "img_height, img_width = 128, 128\n",
    "\n",
    "# Load and preprocess training images\n",
    "num_train = len(X_train_paths)\n",
    "X_train_array = np.zeros((num_train, img_height, img_width, 3), dtype=np.float32)\n",
    "\n",
    "for i, path in enumerate(X_train_paths):\n",
    "    if os.path.exists(path):\n",
    "        img = load_img(path, target_size=(img_height, img_width))\n",
    "        X_train_array[i] = img_to_array(img) / 255.0\n",
    "    else:\n",
    "        print(f\"File not found: {path}\")\n",
    "\n",
    "# Load and preprocess validation images\n",
    "num_valid = len(X_valid_paths)\n",
    "X_valid_array = np.zeros((num_valid, img_height, img_width, 3), dtype=np.float32)\n",
    "\n",
    "for i, path in enumerate(X_valid_paths):\n",
    "    if os.path.exists(path):\n",
    "        img = load_img(path, target_size=(img_height, img_width))\n",
    "        X_valid_array[i] = img_to_array(img) / 255.0\n",
    "    else:\n",
    "        print(f\"File not found: {path}\")\n",
    "\n",
    "print(\"Training shape:\", X_train_array.shape)\n",
    "print(\"Validation shape:\", X_valid_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53cfb0d9-7808-4448-8344-d828794b7d16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Make sure y_train and y_valid exist as numeric labels\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Example: y_train = train_df['label'].values\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#          y_valid = valid_df['label'].values\u001b[39;00m\n\u001b[1;32m     22\u001b[0m svm_classifier \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m svm_classifier\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, \u001b[43my_train\u001b[49m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     26\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m svm_classifier\u001b[38;5;241m.\u001b[39mscore(X_valid_scaled, y_valid)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming your CSV has a column named 'label' with numeric values\n",
    "y_train = train_df['label'].values\n",
    "y_valid = valid_df['label'].values\n",
    "\n",
    "# Flatten images\n",
    "X_train_flat = X_train_array.reshape(len(X_train_array), -1)\n",
    "X_valid_flat = X_valid_array.reshape(len(X_valid_array), -1)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_valid_scaled = scaler.transform(X_valid_flat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe420958-36cc-43eb-9688-5f846caac292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386f9eb-2bb1-4475-972a-68fce7b842ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See Metrics (add confusion matrix and so many more)\n",
    "# Evaluate\n",
    "accuracy = svm_classifier.score(X_valid_scaled, y_valid)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
